% REFERÊNCIAS ALYSON %
@misc{rivery2025,
  author       = {Kevin Bartley},
  title        = {Big data statistics: How much data is there in the world?},
  howpublished = {Blog},
  year         = {2025},
  url          = {https://rivery.io/blog/big-data-statistics-how-much-data-is-there-in-the-world}
}

@misc{google2025,
  author       = {{GOOGLE CLOUD}},
  title        = {O que é machine learning (ML)?},
  howpublished = {Article},
  year         = {s.d.},
  url          = {https://cloud.google.com/learn/what-is-machine-learning?hl=pt-BR}
}

@misc{pedrodomingos2012,
  author       = {Pedro Domingos},
  title        = {A Few Useful Things to Know About Machine Learning},
  howpublished = {Article},
  year         = {2012},
  url          = {https://cacm.acm.org/research/a-few-useful-things-to-know-about-machine-learning}
}

@misc{bashir2020informationtheoreticperspectiveoverfittingunderfitting,
  title         = {An Information-Theoretic Perspective on Overfitting and Underfitting},
  author        = {Daniel Bashir and George D. Montanez and Sonia Sehra and Pedro Sandoval Segura and Julius Lauw},
  year          = {2020},
  eprint        = {2010.06076},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2010.06076}
}

@misc{patel2025,
  author       = {Saumya Patel},
  title        = {Overfitting vs. Underfitting: A Visual Guide for Data Science Beginners},
  howpublished = {Article},
  year         = {2025},
  url          = {https://medium.com/@psaumya567/overfitting-vs-underfitting-a-visual-guide-for-data-science-beginners-4f8b3b961186}
}

@misc{datageeks2025,
  author       = {Pedro César Tebaldi Gomes},
  title        = {Cross Validation: Como Avaliar Modelos em Machine Learning?},
  howpublished = {Article},
  year         = {2025},
  url          = {https://www.datageeks.com.br/cross-validation}
}

@misc{mlmastery2025,
  author       = {Jason Brownlee},
  title        = {How to use Learning Curves to Diagnose Machine Learning Model Performance},
  howpublished = {Article},
  year         = {2019},
  url          = {https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance}
}

@misc{ibm2025_biasvariance,
  author       = {Fanfang Lee},
  title        = {What is bias-variance tradeoff?},
  howpublished = {Article},
  year         = {s.d.},
  url          = {https://www.ibm.com/think/topics/bias-variance-tradeoff}
}

@book{goodfellow-et-al-2016,
  title     = {Deep Learning},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher = {MIT Press},
  note      = {\url{http://www.deeplearningbook.org}},
  year      = {2016}
}

@article{zhalgas2025robustfacerecognition,
  author         = {Zhalgas, Aidana and Amirgaliyev, Beibut and Sovet, Adil},
  title          = {Robust Face Recognition Under Challenging Conditions: A Comprehensive Review of Deep Learning Methods and Challenges},
  journal        = {Applied Sciences},
  volume         = {15},
  year           = {2025},
  number         = {17},
  article-number = {9390},
  url            = {https://www.mdpi.com/2076-3417/15/17/9390},
  issn           = {2076-3417},
  abstract       = {The paper critically reviews face recognition models that are based on deep learning, specifically security and surveillance. Existing systems are susceptible to pose variation, occlusion, low resolution and even aging, even though they perform quite well under controlled conditions. The authors make a systematic review of four state-of-the-art architectures—FaceNet, ArcFace, OpenFace and SFace—through the use of five benchmark datasets, namely LFW, CPLFW, CALFW, AgeDB-30 and QMUL-SurvFace. The measures of performance are evaluated as the area under the receiver operating characteristic (ROC-AUC), accuracy, precision and F1-score. The results reflect that FaceNet and ArcFace achieve the highest accuracy under well-lit and frontal settings; when comparing SFace, this proved to have better robustness to degraded and low-resolution surveillance images. This shows the weaknesses of traditional embedding methods because bigger data sizes reduce the performance of OpenFace with all of the datasets. These results underscore the main point of this study: a comparative study of the models in difficult real life conditions and the observation of the trade-off between generalization and specialization inherent to any models. Specifically, the ArcFace and FaceNet models are optimized to perform well in constrained settings and SFace in the wild ones. This means that the selection of models must be closely monitored with respect to deployment contexts, and future studies should focus on the study of architectures that maintain performance even with fluctuating conditions in the form of the hybrid architectures.},
  doi            = {10.3390/app15179390}
}

@Article{compagnino2025introductionmachinelearning,
AUTHOR = {Compagnino, Antonio Alessio and Maruccia, Ylenia and Cavuoti, Stefano and Riccio, Giuseppe and Tutone, Antonio and Crupi, Riccardo and Pagliaro, Antonio},
TITLE = {An Introduction to Machine Learning Methods for Fraud Detection},
JOURNAL = {Applied Sciences},
VOLUME = {15},
YEAR = {2025},
NUMBER = {21},
ARTICLE-NUMBER = {11787},
URL = {https://www.mdpi.com/2076-3417/15/21/11787},
ISSN = {2076-3417},
ABSTRACT = {Financial fraud represents a critical global challenge with substantial economic and social consequences. This comprehensive review synthesizes the current knowledge on machine learning approaches for financial fraud detection, examining their effectiveness across diverse fraud scenarios. We analyze various fraud types, including credit card fraud, financial statement fraud, insurance fraud, and money laundering, along with their specific detection challenges. The review outlines supervised, unsupervised, and hybrid learning approaches, discussing their applications and performance in different fraud detection contexts. We examine commonly used datasets in fraud detection research and evaluate performance metrics for assessing these systems. The review is further grounded by two case studies applying supervised models to real-world banking data, illustrating the practical challenges of implementing fraud detection systems in operational environments. Through our analysis of the recent literature, we identify persistent challenges, including data imbalance, concept drift, and privacy concerns, while highlighting the emerging trends in deep learning and ensemble methods. This review provides valuable insights for researchers, financial institutions, and practitioners working to develop more effective, adaptive, and interpretable fraud detection systems capable of operating within real-world financial environments.},
DOI = {10.3390/app152111787}
}

@misc{infor2020,
  author       = {{INFOR}},
  title        = {Épocas de crise e supply chain: pandemia exige novos modelos de projeção de demanda},
  howpublished = {Blog},
  year         = {2020},
  url          = {https://www.infor.com/pt-br/blog/seasons-of-crisis-and-supply-chain-pandemic-requires-new-demand-projection-models}
}

% REFERÊNCIAS ELIEL %

@misc{pecanai,
  author       = {PecanAI},
  title        = {Mastering Model Complexity: Avoiding Underfitting and Overfitting Pitfalls},
  howpublished = {Blog},
  year         = {2024},
  month        = {June},
  day          = {13},
  url          = {https://www.pecan.ai/blog/machine-learning-model-underfitting-and-overfitting/},
  note         = {Acesso em: 23 out. 2025}
}

@misc{ultralytics,
  author       = {Ultralytics},
  title        = {Overfitting},
  howpublished = {Blog},
  url          = {https://www.ultralytics.com/glossary/overfitting},
  note         = {Acesso em: 15 out. 2025}
}

@misc{example,
  author       = {},
  title        = {},
  howpublished = {},
  year         = {},
  month        = {},
  day          = {},
  url          = {},
  note         = {}
}