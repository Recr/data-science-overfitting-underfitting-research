\section{Conclusão}

Este estudo explorou overfitting e underfitting como obstáculos centrais à generalização em aprendizado de máquina. A revisão teórica estabeleceu a ligação desses fenômenos ao trade-off viés-variância e a importância de diagnósticos (validação cruzada, curvas de aprendizado). A análise de falhas práticas em sistemas críticos, como reconhecimento facial e detecção de fraude, reiterou o impacto custoso da má generalização.
Foram sistematizadas as técnicas de mitigação: para underfitting, destacam-se o aumento da complexidade do modelo e a engenharia de características; para overfitting, métodos como regularização (L1/L2), Dropout, Data Augmentation e Early Stopping são fundamentais.
Identificou-se uma dicotomia central no estado da arte: a indústria (AutoML) foca em robustecer e automatizar técnicas clássicas para confiabilidade, enquanto a academia desafia a teoria tradicional. O fenômeno da sobreparametrização, onde modelos que interpolam os dados de treino atingem alta generalização, exemplifica essa revisão do consenso.
Conclui-se que, embora o gerenciamento pragmático do trade-off viés-variância seja uma necessidade prática contínua, a compreensão teórica da generalização, especialmente em deep learning, está em plena evolução e longe de ser um problema solucionado. Consequentemente, podemos afirmar que há um certo perigo para áreas críticas que dependem de modelos de ML, caso a pesquisa não avance para reconciliar teoria e prática. Assim, este trabalho contribui para o entendimento dos desafios e soluções em overfitting e underfitting, destacando a necessidade de pesquisas futuras que aprofundem a compreensão teórica e aprimorem as práticas industriais.